{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ7xJLWpKywk",
        "outputId": "d2648ff6-22ec-4b1f-b897-30732f5dcadc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at ./gdrive; to attempt to forcibly remount, call drive.mount(\"./gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98RTGbi8L6BQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, AutoModelForSequenceClassification, TrainingArguments\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31FMzz4xK24a",
        "outputId": "3669a710-1afe-44d6-db37-8b75676fafca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7779"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "\n",
        "DUMP_DIR = \"./gdrive/MyDrive/dumps\"\n",
        "\n",
        "if not os.path.exists(DUMP_DIR):\n",
        "    os.makedirs(DUMP_DIR, exist_ok = True)\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "path = DUMP_DIR + '/adv-text.dat'\n",
        "\n",
        "\n",
        "if not Path(path).is_file():\n",
        "    # retrievedFiles.append(defaultdict(int))\n",
        "    raise \"File not found. Please generate adversarial text first\"\n",
        "# else:\n",
        "with open(path, \"rb\") as f:\n",
        "    adversarial_texts = pickle.load(f)\n",
        "len(adversarial_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TwSqzYbLHCP",
        "outputId": "e7d0c37f-8345-4ee6-d233-cfea2910a1ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[' sooo melancholic i will miss you here in san clemente!!! ',\n",
              "  0.9918066,\n",
              "  0,\n",
              "  -1,\n",
              "  ' sooo sad i will miss you here in san diego!!! '],\n",
              " ['my boss is bullying me... ',\n",
              "  0.9966323,\n",
              "  0,\n",
              "  -1,\n",
              "  'my boss is bullying me... ']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "adversarial_texts[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d49Rt5tLqsL"
      },
      "source": [
        "## Load Tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7ceVnRTMfPk",
        "outputId": "cefbe417-96f4-4f76-9ebc-66199e6d1505"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5046, 5046)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "original_neg_sentences = [i[4] for i in adversarial_texts if i[3] != -1]\n",
        "adv_sentences = [i[0] for i in adversarial_texts if i[3] != -1]\n",
        "len(original_neg_sentences), len(adv_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6cifKASgLxpd",
        "outputId": "59260ae9-a738-4f24-95a7-552286d8eeee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       textID                                               text  \\\n",
              "0  cb774db0d1               i`d have responded, if i were going    \n",
              "1  549e992a42     sooo sad i will miss you here in san diego!!!    \n",
              "2  088c60f138                         my boss is bullying me...    \n",
              "3  9642c003ef                    what interview! leave me alone    \n",
              "4  358bd9e861   sons of ****, why couldn`t they put them on t...   \n",
              "\n",
              "                         selected_text sentiment  label  \n",
              "0  I`d have responded, if I were going   neutral      1  \n",
              "1                             Sooo SAD  negative      0  \n",
              "2                          bullying me  negative      0  \n",
              "3                       leave me alone  negative      0  \n",
              "4                        Sons of ****,  negative      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0659a05-8d8e-4ffb-ad67-f35bd8649de9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>i`d have responded, if i were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0659a05-8d8e-4ffb-ad67-f35bd8649de9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e0659a05-8d8e-4ffb-ad67-f35bd8649de9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e0659a05-8d8e-4ffb-ad67-f35bd8649de9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-48b159e1-ad85-492f-800a-bd067e117aac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-48b159e1-ad85-492f-800a-bd067e117aac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-48b159e1-ad85-492f-800a-bd067e117aac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df = pd.read_csv('./gdrive/MyDrive/data/tweets_preprocessed.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[11415]['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FSA67HXIA7q7",
        "outputId": "9868c86e-7005-40b7-8b24-4c8c234aae1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1am, quietly tidying up after dinner party. whilst closing tupperware lid, centre island in my kitchen collapses! wakes baby. mayhem ensues '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_LSTyrmMBw9"
      },
      "outputs": [],
      "source": [
        "# replace text with adv\n",
        "\n",
        "newText = []\n",
        "\n",
        "for ind, row in df.iterrows():\n",
        "    try:\n",
        "        idx = original_neg_sentences.index(row['text'])\n",
        "        if adversarial_texts[3] != -1:\n",
        "          newText.append(adv_sentences[idx])\n",
        "    except:\n",
        "        newText.append(row['text'])\n",
        "\n",
        "df['text'] = newText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YBpMc0Yyig-I",
        "outputId": "3915c9e7-8649-4fa2-ee23-0ac5a01f71ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1am, peaceably tidying up after dinner party. whilst closing tupperware lid, centre island in my kitchen crumble! wakes baby. mayhem ensues '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df.iloc[11415]['text']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i34kecOZjYVv"
      },
      "source": [
        "# Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNVeCrtaNS2V",
        "outputId": "6d275d44-a4a0-4921-8ffb-e4d57794e8a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification at 0x7e589d3117b0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"MarieAngeA13/Sentiment-Analysis-BERT\")\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"./gdrive/MyDrive/tweet_classification\")\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaZ6bJmSleeS",
        "outputId": "2e0b2562-e430-412d-e6bc-7aa2708d2bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27480 entries, 0 to 27479\n",
            "Data columns (total 5 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   textID         27480 non-null  object\n",
            " 1   text           27480 non-null  object\n",
            " 2   selected_text  27480 non-null  object\n",
            " 3   sentiment      27480 non-null  object\n",
            " 4   label          27480 non-null  int64 \n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 1.0+ MB\n"
          ]
        }
      ],
      "source": [
        "df['text'] = df['text'].astype('str')\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now use predict function"
      ],
      "metadata": {
        "id": "h7yhc18b8oVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, tokenizer, text):\n",
        "    embedding_matrix = model.bert.embeddings.weights[0]\n",
        "    encoded_tokens = tokenizer(text, padding=\"max_length\", max_length = 128, truncation=True, return_tensors=\"tf\")\n",
        "    token_ids = list(encoded_tokens[\"input_ids\"].numpy()[0])\n",
        "    vocab_size = embedding_matrix.get_shape()[0]\n",
        "\n",
        "    # convert token ids to one hot\n",
        "    token_ids_tensor = tf.constant([token_ids], dtype='int32')\n",
        "    token_ids_tensor_one_hot = tf.one_hot(token_ids_tensor, vocab_size)\n",
        "\n",
        "    inputs_embeds = tf.matmul(token_ids_tensor_one_hot, embedding_matrix)\n",
        "    pred_scores = model({\"inputs_embeds\": inputs_embeds, \"attention_mask\": encoded_tokens[\"attention_mask\"]}).logits\n",
        "    max_class = tf.argmax(pred_scores, axis=1).numpy()[0]\n",
        "\n",
        "    return max_class"
      ],
      "metadata": {
        "id": "5h4nXfYU8q5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "id": "kweH9H2yCEWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjYKFkayKS4R"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.text, df.label, test_size=.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "ds = DatasetDict()\n",
        "ds[\"train\"] = Dataset.from_pandas(pd.DataFrame(zip(X_train, y_train), columns=[\"text\", \"label\"]))\n",
        "ds[\"test\"] = Dataset.from_pandas(pd.DataFrame(zip(X_test, y_test), columns=[\"text\", \"label\"]))\n",
        "\n",
        "ds[\"train\"][10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5acukOACeoP",
        "outputId": "84d73be2-bb39-4921-a49f-1dc7328845d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': \"ninja sushi for lunch but dominic's was out of sour gummy worms \",\n",
              " 'label': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, tokenizer, ds['test']['text'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAHc747YEI67",
        "outputId": "46e3b9fb-b322-4538-ff99-131358f21505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 0.00034027753)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['test']['label'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkPN-WysMw_K",
        "outputId": "7a5287db-3f17-49df-c448-bc8698657770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(model, tokenizer, dataset):\n",
        "    correct_predictions = 0\n",
        "    total_samples = len(dataset[\"label\"])\n",
        "\n",
        "    for i in range(total_samples):\n",
        "        text = dataset[\"text\"][i]\n",
        "        label = dataset[\"label\"][i]\n",
        "\n",
        "        # Make prediction\n",
        "        predicted_class = predict(model, tokenizer, text)\n",
        "\n",
        "        # Check accuracy\n",
        "        if predicted_class == label:\n",
        "            correct_predictions += 1\n",
        "        if i % 50 == 0:\n",
        "          print(f\"{i + 1} items prediced\")\n",
        "    print(f'correct predictions: {correct_predictions}')\n",
        "    print(f'total samples: {total_samples}')\n",
        "    accuracy = correct_predictions / total_samples\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "d1p7kOvSFCOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = calculate_accuracy(model, tokenizer, ds['test'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdI6dL9PFDzp",
        "outputId": "8efd2f38-8979-4c15-dcd3-b531623118ff"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 items prediced\n",
            "51 items prediced\n",
            "101 items prediced\n",
            "151 items prediced\n",
            "201 items prediced\n",
            "251 items prediced\n",
            "301 items prediced\n",
            "351 items prediced\n",
            "401 items prediced\n",
            "451 items prediced\n",
            "501 items prediced\n",
            "551 items prediced\n",
            "601 items prediced\n",
            "651 items prediced\n",
            "701 items prediced\n",
            "751 items prediced\n",
            "801 items prediced\n",
            "851 items prediced\n",
            "901 items prediced\n",
            "951 items prediced\n",
            "1001 items prediced\n",
            "1051 items prediced\n",
            "1101 items prediced\n",
            "1151 items prediced\n",
            "1201 items prediced\n",
            "1251 items prediced\n",
            "1301 items prediced\n",
            "1351 items prediced\n",
            "1401 items prediced\n",
            "1451 items prediced\n",
            "1501 items prediced\n",
            "1551 items prediced\n",
            "1601 items prediced\n",
            "1651 items prediced\n",
            "1701 items prediced\n",
            "1751 items prediced\n",
            "1801 items prediced\n",
            "1851 items prediced\n",
            "1901 items prediced\n",
            "1951 items prediced\n",
            "2001 items prediced\n",
            "2051 items prediced\n",
            "2101 items prediced\n",
            "2151 items prediced\n",
            "2201 items prediced\n",
            "2251 items prediced\n",
            "2301 items prediced\n",
            "2351 items prediced\n",
            "2401 items prediced\n",
            "2451 items prediced\n",
            "2501 items prediced\n",
            "2551 items prediced\n",
            "2601 items prediced\n",
            "2651 items prediced\n",
            "2701 items prediced\n",
            "2751 items prediced\n",
            "2801 items prediced\n",
            "2851 items prediced\n",
            "2901 items prediced\n",
            "2951 items prediced\n",
            "3001 items prediced\n",
            "3051 items prediced\n",
            "3101 items prediced\n",
            "3151 items prediced\n",
            "3201 items prediced\n",
            "3251 items prediced\n",
            "3301 items prediced\n",
            "3351 items prediced\n",
            "3401 items prediced\n",
            "3451 items prediced\n",
            "3501 items prediced\n",
            "3551 items prediced\n",
            "3601 items prediced\n",
            "3651 items prediced\n",
            "3701 items prediced\n",
            "3751 items prediced\n",
            "3801 items prediced\n",
            "3851 items prediced\n",
            "3901 items prediced\n",
            "3951 items prediced\n",
            "4001 items prediced\n",
            "4051 items prediced\n",
            "4101 items prediced\n",
            "4151 items prediced\n",
            "4201 items prediced\n",
            "4251 items prediced\n",
            "4301 items prediced\n",
            "4351 items prediced\n",
            "4401 items prediced\n",
            "4451 items prediced\n",
            "4501 items prediced\n",
            "4551 items prediced\n",
            "4601 items prediced\n",
            "4651 items prediced\n",
            "4701 items prediced\n",
            "4751 items prediced\n",
            "4801 items prediced\n",
            "4851 items prediced\n",
            "4901 items prediced\n",
            "4951 items prediced\n",
            "5001 items prediced\n",
            "5051 items prediced\n",
            "5101 items prediced\n",
            "5151 items prediced\n",
            "5201 items prediced\n",
            "5251 items prediced\n",
            "5301 items prediced\n",
            "5351 items prediced\n",
            "5401 items prediced\n",
            "5451 items prediced\n",
            "5501 items prediced\n",
            "5551 items prediced\n",
            "5601 items prediced\n",
            "5651 items prediced\n",
            "5701 items prediced\n",
            "5751 items prediced\n",
            "5801 items prediced\n",
            "5851 items prediced\n",
            "5901 items prediced\n",
            "5951 items prediced\n",
            "6001 items prediced\n",
            "6051 items prediced\n",
            "6101 items prediced\n",
            "6151 items prediced\n",
            "6201 items prediced\n",
            "6251 items prediced\n",
            "6301 items prediced\n",
            "6351 items prediced\n",
            "6401 items prediced\n",
            "6451 items prediced\n",
            "6501 items prediced\n",
            "6551 items prediced\n",
            "6601 items prediced\n",
            "6651 items prediced\n",
            "6701 items prediced\n",
            "6751 items prediced\n",
            "6801 items prediced\n",
            "6851 items prediced\n",
            "6901 items prediced\n",
            "6951 items prediced\n",
            "7001 items prediced\n",
            "7051 items prediced\n",
            "7101 items prediced\n",
            "7151 items prediced\n",
            "7201 items prediced\n",
            "7251 items prediced\n",
            "7301 items prediced\n",
            "7351 items prediced\n",
            "7401 items prediced\n",
            "7451 items prediced\n",
            "7501 items prediced\n",
            "7551 items prediced\n",
            "7601 items prediced\n",
            "7651 items prediced\n",
            "7701 items prediced\n",
            "7751 items prediced\n",
            "7801 items prediced\n",
            "7851 items prediced\n",
            "7901 items prediced\n",
            "7951 items prediced\n",
            "8001 items prediced\n",
            "8051 items prediced\n",
            "8101 items prediced\n",
            "8151 items prediced\n",
            "8201 items prediced\n",
            "correct predictions: 5733\n",
            "total samples: 8244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZRU96ZKFJBl",
        "outputId": "f386e400-80d9-4573-e60c-4e90dec46a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7029702970297029"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}